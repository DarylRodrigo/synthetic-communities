# Synthetic Community

*A high‑level system design for simulating public discussions and elections with agents, media, and feedback loops.*

## 1) Purpose & Vision

Synthetic Community models how ideas compete, spread, and convert people in a civic context. It simulates:

* **Debates** among **Candidates** moderated by a **Mediator**.
* **Personas** (citizens) who read, converse, post on **Social Media**, and eventually **vote**.
* **Feedback loops** where discourse shifts opinions, which in turn changes discourse.

**Primary goals**

* Enable controlled experiments on messaging, platform rules, and voting methods.
* Provide transparent abstractions that can map to multiple behavioral / opinion-dynamics models.
* Produce reproducible, inspectable simulations with rich telemetry.

**Non‑goals**

* Predict real elections.
* Model every sociological nuance; we aim for modular approximations.

## 2) Core Concepts (Domain Model)

### Topic

* The focal question or theme (e.g., *“Who should be Prime Minister?”* or *“Is policy X a good idea?”*).
* Properties: `id`, `title`, `description`, `tags`, `stance_axis` (e.g., pro vs con), `complexity`.
* May be generated by the **Mediator** or pre-seeded by the experiment.

### Candidates

* Agents who advocate stances and attempt to persuade.
* Properties: `id`, `name`, `party/affiliation`, `policy_positions` (per topic), `strategy` (messaging tactic), `memory` (what they’ve said/learned), `targeting_rules`.
* Behaviors: read the room (social signals), craft arguments, reply during debate, adjust messaging.

### Personas (Population)

* Citizens with heterogeneous traits and networks who ultimately vote.
* Properties: `id`, `demographics` (abstracted), `traits` (e.g., Big Five or custom), `priors` (beliefs, salience, trust frames), `media_diet`, `susceptibility` (influenceability), `social_graph_refs`, `voting_pref`, `fatigue`, `memory`.
* Behaviors: consume debate/media, update beliefs, chat with friends, post occasionally, vote.

### Social Media (Platform Layer)

* A shared information surface where personas (and optionally candidates) post and react.
* Properties: `feed_ranking_rules`, `visibility_caps`, `virality_function`, `moderation_rules`, `bot/noise_rate`.
* Artifacts: `posts`, `replies`, `reactions` (like/upvote), `engagement_metrics`.

### Mediator

* Orchestrates formal debate turns and curates topics; enforces time/turn limits.
* Properties: `topic_sampler`, `fairness_rules`, `moderation_flags`, `time_budget`.
* Behaviors: propose topic → collect candidate responses → ensure balanced floor time → publish debate transcript.

### Game Loop (Epoch → Debate → Social Diffusion → Vote)

* Encodes the simulation steps and their order (see Section 4).

## 3) System Architecture (High‑Level)

**Layers**

1. **Experiment Orchestrator** – seeds scenarios, sets knobs (n, k, population size, voting rule), runs multiple trials, handles checkpoints.
2. **Agent Layer** – Candidate agents, Persona agents (pluggable cognition/update models).
3. **Interaction Layer** – Mediator (debate protocol), Social Media (posting, ranking, reactions), Peer‑to‑Peer chats.
4. **Dynamics & Update Layer** – Opinion updates, trust updates, fatigue, alignment with identity, network diffusion.
5. **Outcome Layer** – Voting mechanics and result aggregation.
6. **Observability Layer** – Metrics, logging, audits, artifacts (debate transcripts, feed snapshots, network diffs), experiment registry.

**Modularity principles**

* Every behavioral function is an interface (strategy pattern) so different models can be swapped in (e.g., bounded‑confidence vs Bayesian vs heuristic rules).
* Deterministic seeds + pure functions where possible; stochastic sources isolated for reproducibility.
* Config‑driven runs; all parameters captured in a single run manifest.

## 4) Simulation Lifecycle (Single Epoch)

Given `n` debate topics per epoch and `k` turns per topic:

1. **Candidates read social media** (sensemaking):

   * Pull platform signals (top posts, sentiment, salience) and update candidate internal state.

2. **For i in 1..n (topics per epoch)**

   * **Mediator proposes Topic i** (from seed list or generator).
   * **For t in 1..k (debate turns)**

     * Candidates produce statements/arguments.
     * Mediator enforces order, time, and fairness; flags moderation issues.
   * **Publish debate transcript** (structured messages tagged by topic, turn, speaker, stance).

3. **Population consumes debate**

   * Personas read transcript or summaries according to their media_diet and attention budget.

4. **Personas update internal state**

   * Update beliefs, salience weights, candidate trust, fatigue, and turnout propensity using the selected opinion‑dynamics model.

5. **Personas chat with friends**

   * Simulate peer‑to‑peer diffusion on the social graph (gossip, DM, group chat). Influence propagates along edges with decay and homophily effects.

6. **Personas update beliefs again** (post‑social diffusion consolidation)

   * Apply network effects; adjust uncertainty and conviction.

7. **Subsection of population posts on social media**

   * Sample posters by activity propensity; create posts derived from current beliefs, with noise and style variation.

8. **Population votes on posts** (reactions/engagement)

   * Apply feed ranking and virality; collect engagement telemetry.

9. **(Optional) Interim polling**

   * Sample intent/approval to track momentum.

10. **Repeat** for subsequent epochs or proceed to **Voting** (Section 7).

## 5) Opinion‑Dynamics & Update Models (Pluggable)

* **Bayesian‑ish update**: priors × likelihood from message credibility; identity‑protective cognition caps extremes.
* **Bounded confidence** (Hegselmann‑Krause): only consider messages within an acceptance radius.
* **Influence maximization heuristic**: exposure counts × trust weights × recency decay.
* **Elaboration likelihood**: central vs peripheral route depending on persona attention/fatigue.
* **Backfire / reactance**: probability of moving away from message if it threatens identity.
* **Echo‑chamber & homophily**: network assortativity reduces cross‑cutting exposure unless forced.

Each run selects **one** or composes several via weighted blending. Parameters recorded in the run manifest.

## 6) Social Media Mechanics

* **Feed ranking**: function of engagement, freshness, interpersonal proximity, viewpoint diversity quota.
* **Virality**: branching process with saturation and novelty penalties.
* **Moderation**: content policy hooks (remove, downrank, label); configurable strictness.
* **Noise & bots**: background rate to test robustness.
* **Observability**: snapshots of top‑K posts, reach distributions, and exposure by cohort.

## 7) Voting & Outcomes

Support multiple rules to study system sensitivity:

* **Plurality** (first‑past‑the‑post)
* **Runoff / Two‑round**
* **Ranked‑Choice Voting (IRV)**
* **Approval Voting**
* **Score Voting**

Outputs: winner(s), margins, turnout, cohort‑level shifts, calibration vs interim polling.

## 8) Data & Artifacts (No Code)

* **Run Manifest**: scenario id, seeds, parameters (`n`, `k`, population size, update model, platform rules, voting rule, time budgets).
* **Debate Transcript**: structured records per turn (speaker, topic, stance, content summary, moderation flags).
* **Persona Snapshots**: beliefs vector, salience, trust, turnout propensity, fatigue, media_diet.
* **Network State**: adjacency summary, centralities, community assignments.
* **Social Feed**: posts with metadata (author cohort, exposures, reactions, reach, flags).
* **Telemetry**: per‑step metrics, histograms, timeseries.
* **Final Outcomes**: vote records (by rule), diagnostics, audits.

All artifacts versioned; ensure determinism under fixed seeds.

## 9) Configuration Knobs (Examples)

* **Scale**: population size, graph type (ER, SBM, small‑world), average degree.
* **Debate**: `n` topics/epoch, `k` turns/topic, mediator strictness.
* **Messaging**: candidate strategies (appeal to base, broaden tent, attack/contrast, data‑driven).
* **Cognition**: susceptibility distribution, bounded‑confidence radius, reactance rate, fatigue curve.
* **Platform**: ranking weights, diversity quota, moderation thresholds, bot rate.
* **Voting**: rule, turnout function, ballots (ordinal/cardinal).

## 10) Metrics & Evaluation

**Process metrics**: exposure counts, dwell time proxy, diversity of viewpoints consumed, debate balance, moderation interventions.
**State metrics**: belief distributions (mean/variance), polarization indices, network modularity changes, trust in candidates.
**Outcome metrics**: vote share, margins, turnout, winner stability across rules, sensitivity to parameter perturbations.
**Fairness/health**: representation balance, over‑amplification of extreme content, misinformation prevalence.

## 11) Experiment Design Patterns

* **A/B interventions**: vary one knob (e.g., ranking diversity) and compare outcome deltas.
* **Counterfactual replays**: re‑run same epoch with altered candidate strategy or moderation.
* **Stress tests**: inject bot floods or misinformation spikes; measure resilience.
* **Parameter sweeps**: grid/random search over cognition and platform parameters.

All experiments logged to a registry with seeds, manifests, and summaries.

## 15) Glossary (Quick)

* **Epoch**: one full cycle of debate → diffusion → posting → reactions.
* **n**: topics per epoch. **k**: turns per topic.
* **Stance axis**: coarse representation of positions on a topic.
* **Salience**: how much a topic matters to a persona.
* **Homophily**: tendency to connect with similar others.

### Summary

Synthetic Community is a modular sandbox for studying how debates, platforms, and social networks shape collective outcomes. It emphasizes clarity, swap‑able models, and reproducible experiments—without prescribing a single “true” social theory.
